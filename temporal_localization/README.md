Temporal localization
===

> 'Temporal Action Localization' / 'Temporal (Action) Proposal Generation'

> [Github Awesome Temporal Action Localization](https://github.com/Alvin-Zeng/Awesome-Temporal-Action-Localization) [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/Alvin-Zeng/Awesome-Temporal-Action-Localization)
>
> **[Temporal Action Localization | Papers With Code](https://paperswithcode.com/task/action-recognition)**
> * Datasets (might also mix with the _action recognition_ task): UCF101, Kinetics, HMDB51, ActivityNet, THUMOS'14, JHMDB
>
> **[Temporal Action Proposal Generation | Papers With Code](https://paperswithcode.com/task/temporal-action-proposal-generation)**
> * Datasets: ActivityNet, THUMOS'14
>
> [Action Localization Models â€” MMAction2 0.24.1 documentation](https://mmaction2.readthedocs.io/en/latest/localization_models.html)

* BMN: Boundary-Matching Network for Temporal Action Proposal Generation [[arXiv abstract]](https://arxiv.org/abs/1907.09702) [[pdf]](1907.09702.pdf)
[[Official Github - PaddlePaddle]](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/video/models/bmn) [[MMAction2 readthedocs]](https://mmaction2.readthedocs.io/en/latest/localization_models.html#bmn)

* BSN: Boundary Sensitive Network for Temporal Action Proposal Generation [[arXiv abstract]](https://arxiv.org/abs/1806.02964) [[pdf]](1806.02964.pdf) [[github code]](https://github.com/wzmsltw/BSN-boundary-sensitive-network.pytorch) [[MMAction2 readthedocs]](https://mmaction2.readthedocs.io/en/latest/localization_models.html#bsn)

* SSN: Temporal Action Detection with Structured Segment Networks [[arXiv abstract]](https://arxiv.org/abs/1704.06228) [[pdf]](1704.06228.pdf) [[MMAction2 readthedocs]](https://mmaction2.readthedocs.io/en/latest/localization_models.html#ssn)

* LACP: Learning Action Completeness from Points for Weakly-supervised Temporal Action Localization
[[arXiv abstract]](https://arxiv.org/abs/2108.05029) [[pdf]](2108.05029.pdf)
[[github code]](https://github.com/Pilhyeon/Learning-Action-Completeness-from-Points)
  > Ranked #1 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/learning-action-completeness-from-points-for/weakly-supervised-action-localization-on-1)](https://paperswithcode.com/sota/weakly-supervised-action-localization-on-1?p=learning-action-completeness-from-points-for)
  >
  > Ranked #1 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/learning-action-completeness-from-points-for/weakly-supervised-action-localization-on-5)](https://paperswithcode.com/sota/weakly-supervised-action-localization-on-5?p=learning-action-completeness-from-points-for)

* ASM-Loc: Action-aware Segment Modeling for Weakly-Supervised Temporal Action Localization [[arXiv abstract]](https://arxiv.org/abs/2203.15187) [[pdf]](2203.15187.pdf) [[github code]](https://github.com/boheumd/asm-loc)
  > Ranked #1 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/asm-loc-action-aware-segment-modeling-for/weakly-supervised-action-localization-on-1)](https://paperswithcode.com/sota/weakly-supervised-action-localization-on-1?p=asm-loc-action-aware-segment-modeling-for)
  >
  > Ranked #2 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/asm-loc-action-aware-segment-modeling-for/weakly-supervised-action-localization-on)](https://paperswithcode.com/sota/weakly-supervised-action-localization-on?p=asm-loc-action-aware-segment-modeling-for)

* BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation [[arXiv abstract]](https://arxiv.org/abs/2009.07641) [[pdf]](2009.07641.pdf) [[github code]](https://github.com/xxcheng0708/BSNPlusPlus-boundary-sensitive-network)

* E2E-TAD: An Empirical Study of End-to-End Temporal Action Detection [[arXiv abstract]](https://arxiv.org/abs/2204.02932) [[pdf]](2204.02932.pdf) [[github code]](https://github.com/xlliu7/E2E-TAD)
  > After math of the TadTR work

* TadTR: End-to-end Temporal Action Detection with Transformer [[arXiv abstract]](https://arxiv.org/abs/2106.10271) [[pdf]](2106.10271.pdf) [[github code]](https://github.com/xlliu7/TadTR)
  > Improved on the work of E2E-TAD

* DBG Fast Learning of Temporal Action Proposal via Dense Boundary Generator [[arXiv abstract]](https://arxiv.org/abs/1911.04127) [[pdf]](1911.04127.pdf) [[github code]](https://github.com/Tencent/ActionDetection-DBG)

* TDN: Temporal Difference Networks for Efficient Action Recognition [[arXiv abstract]](https://arxiv.org/abs/2012.10071) [[pdf]](2012.10071.pdf) [[github code]](https://github.com/MCG-NJU/TDN)
  > Ranked #17 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tdn-temporal-difference-networks-for/action-recognition-in-videos-on-something)](https://paperswithcode.com/sota/action-recognition-in-videos-on-something?p=tdn-temporal-difference-networks-for)
  >
  > Ranked #5 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tdn-temporal-difference-networks-for/action-recognition-in-videos-on-something-1)](https://paperswithcode.com/sota/action-recognition-in-videos-on-something-1?p=tdn-temporal-difference-networks-for)

* ActionFormer: Localizing Moments of Actions with Transformers [[arXiv abstract]](https://arxiv.org/abs/2202.07925) [[pdf]](2202.07925.pdf) [[github code]](https://github.com/happyharrycn/actionformer_release)

* TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks [[arXiv abstract]](https://arxiv.org/abs/2011.11479) [[pdf]](2011.11479.pdf) [[github code]](https://github.com/HumamAlwassel/TSP)
  > Ranked #10 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tsp-temporally-sensitive-pretraining-of-video/temporal-action-localization-on-activitynet)](https://paperswithcode.com/sota/temporal-action-localization-on-activitynet?p=tsp-temporally-sensitive-pretraining-of-video)
  >
  > Ranked #3 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tsp-temporally-sensitive-pretraining-of-video/temporal-action-proposal-generation-on)](https://paperswithcode.com/sota/temporal-action-proposal-generation-on?p=tsp-temporally-sensitive-pretraining-of-video)
  >
  > Ranked #5 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tsp-temporally-sensitive-pretraining-of-video/dense-video-captioning-on-activitynet)](https://paperswithcode.com/sota/dense-video-captioning-on-activitynet?p=tsp-temporally-sensitive-pretraining-of-video)
  >
  > Ranked #8 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tsp-temporally-sensitive-pretraining-of-video/temporal-action-localization-on-thumos14)](https://paperswithcode.com/sota/temporal-action-localization-on-thumos14?p=tsp-temporally-sensitive-pretraining-of-video)

* TALLFormer: Temporal Action Localization with a Long-memory Transformer [[arXiv abstract]](https://arxiv.org/abs/2204.01680) [[pdf]](2204.01680.pdf) [[github code]](https://github.com/klauscc/tallformer)

* AEI: Actors-Environment Interaction with Adaptive Attention for Temporal Action Proposals Generation [[arXiv abstract]](https://arxiv.org/abs/2110.11474) [[pdf]](2110.11474.pdf) [[github code]](https://github.com/vhvkhoa/tapg-agentenvinteration)
  > Ranked #1 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/aei-actors-environment-interaction-with/temporal-action-proposal-generation-on)](https://paperswithcode.com/sota/temporal-action-proposal-generation-on?p=aei-actors-environment-interaction-with)
  >
  > âš ï¸ Requires environment and actor features doing respectively 80 and 215 GB!!

* RTD-Net: Relaxed Transformer Decoders for Direct Action Proposal Generation [[arXiv abstract]](https://arxiv.org/abs/2102.01894) [[pdf]](2102.01894.pdf) [[github code]](https://github.com/MCG-NJU/RTD-Action)

* TSM: Temporal Shift Module for Efficient Video Understanding [[arXiv abstract]](https://arxiv.org/abs/1811.08383) [[pdf]](1811.08383.pdf) [[github code]](https://github.com/mit-han-lab/temporal-shift-module)
  > it can achieve the performance of 3D CNN but maintain 2D CNN's complexity

* TSN: Temporal Segment Networks for Action Recognition in Videos [[arXiv abstract]](https://arxiv.org/abs/1705.02953) [[pdf]](1705.02953.pdf) [[github code]](https://github.com/yjxiong/temporal-segment-networks)

* UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation [[arXiv abstract]](https://arxiv.org/abs/2002.06353) [[pdf]](2002.06353.pdf) [[github code]](https://github.com/microsoft/UniVL)

* YOWO: You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization [[arXiv abstract]](https://arxiv.org/abs/1911.06644) [[pdf]](1911.06644.pdf) [[github code]](https://github.com/wei-tim/YOWO)
  > CNN architecture for real-time spatiotemporal action localization in video stream

* AFSD: Learning Salient Boundary Feature for Anchor-free Temporal Action Localization [[arXiv abstract]](https://arxiv.org/abs/2103.13137) [[pdf]](2103.13137.pdf) [[github code]](https://github.com/TencentYoutuResearch/ActionDetection-AFSD)
[[pretrained models - Google Drive]](https://drive.google.com/drive/folders/1IG51-hMHVsmYpRb_53C85ISkpiAHfeVg)

* SSTAP: Self-Supervised Learning for Semi-Supervised Temporal Action Proposal
[[arXiv abstract]](https://arxiv.org/abs/2104.03214) [[github code]](https://github.com/wangxiang1230/SSTAP)
[[SSTAP_TSN_Model_Weights | Zenodo]](https://zenodo.org/record/5036065#.Yv4HxuxBweb)

* MUSES: Multi-shot Temporal Event Localization: a Benchmark [[arXiv abstract]](https://arxiv.org/abs/2012.09434) [[pdf]](2012.09434.pdf) [[github code]](https://github.com/xlliu7/MUSES)
  > Ranked #5 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/multi-shot-temporal-event-localization-a/temporal-action-localization-on-thumos14)](https://paperswithcode.com/sota/temporal-action-localization-on-thumos14?p=multi-shot-temporal-event-localization-a)

* CoLA: Weakly-Supervised Temporal Action Localization with Snippet Contrastive Learning [[arXiv abstract]](https://arxiv.org/abs/2103.16392) [[pdf]](2103.16392.pdf) [[github code]](https://github.com/zhang-can/CoLA)

* TCANet: Temporal Context Aggregation Network for Temporal Action Proposal Refinement [[arXiv abstract]](https://arxiv.org/abs/2103.13141) [[pdf]](2103.13141.pdf) [[github code]](https://github.com/qinzhi-0110/Temporal-Context-Aggregation-Network-Pytorch)

* DCAN: Improving Temporal Action Detection via Dual Context Aggregation [[arXiv abstract]](https://arxiv.org/abs/2112.03612) [[pdf]](2112.03612.pdf) [[github code]](https://github.com/cg1177/DCAN)

* TAM: Temporal Adaptive Module for Video Recognition [[arXiv abstract]](https://arxiv.org/abs/2005.06803) [[pdf]](2005.06803.pdf) [[github code]](https://github.com/liu-zhy/temporal-adaptive-module)
  > Video data is with complex temporal dynamics due to various factors such as camera motion, speed variation, and different activities

* **End-to-end Learning of Action Detection from Frame Glimpses in Videos** [[arXiv abstract]](https://arxiv.org/abs/1511.06984) [[pdf]](1511.06984.pdf)
  > Seeks frames from variable distances, forward and as well backwards

* SF-Net: Single-Frame Supervision for Temporal Action Localization
[[arXiv abstract]](https://arxiv.org/abs/2003.06845) [[pdf]](2003.06845.pdf) [[github code]](https://github.com/Flowerfan/SF-Net)
  > Model telling which frame to seek next (example: go forward of 2.4s)
  >
  > Doesn't provide trained model... ðŸ˜¢
  >
  > Ranked #7 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/sf-net-single-frame-supervision-for-temporal/weakly-supervised-action-localization-on)](https://paperswithcode.com/sota/weakly-supervised-action-localization-on?p=sf-net-single-frame-supervision-for-temporal)

* AdaFrame: Adaptive Frame Selection for Fast Video Recognition [[arXiv abstract]](https://arxiv.org/abs/1811.12432) [[pdf]](1811.12432.pdf)

* CTAP: Complementary Temporal Action Proposal Generation [[arXiv abstract]](https://arxiv.org/abs/1807.04821) [[pdf]](1807.04821.pdf)
[[github code]](https://github.com/jiyanggao/CTAP)

* SmallBigNet: Integrating Core and Contextual Views for Video Classification [[arXiv abstract]](https://arxiv.org/abs/2006.14582) [[pdf]](2006.14582.pdf) [[github code]](https://github.com/xhl-video/SmallBigNet)

* X3D: Expanding Architectures for Efficient Video Recognition [[arXiv abstract]](https://arxiv.org/abs/2004.04730) [[pdf]](2004.04730.pdf)

* STM: SpatioTemporal and Motion Encoding for Action Recognition [[arXiv abstract]](https://arxiv.org/abs/1908.02486) [[pdf]](1908.02486.pdf)

* TEA: Temporal Excitation and Aggregation for Action Recognition [[arXiv abstract]](https://arxiv.org/abs/2004.01398) [[pdf]](2004.01398.pdf)