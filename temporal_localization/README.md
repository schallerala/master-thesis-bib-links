Temporal localization
===

> 'Temporal Action Localization' / 'Temporal (Action) Proposal Generation'

> [Github Awesome Temporal Action Localization](https://github.com/Alvin-Zeng/Awesome-Temporal-Action-Localization) [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/Alvin-Zeng/Awesome-Temporal-Action-Localization)
>
> **[Temporal Action Localization | Papers With Code](https://paperswithcode.com/task/action-recognition)**
> * Datasets (might also mix with the _action recognition_ task): UCF101, Kinetics, HMDB51, ActivityNet, THUMOS'14, JHMDB
>
> **[Temporal Action Proposal Generation | Papers With Code](https://paperswithcode.com/task/temporal-action-proposal-generation)**
> * Datasets: ActivityNet, THUMOS'14
>
> [Action Localization Models — MMAction2 0.24.1 documentation](https://mmaction2.readthedocs.io/en/latest/localization_models.html)

* BMN: Boundary-Matching Network for Temporal Action Proposal Generation [[arXiv abstract]](https://arxiv.org/abs/1907.09702) [[pdf]](1907.09702)
[[Official Github - PaddlePaddle]](https://github.com/PaddlePaddle/models/tree/develop/PaddleCV/video/models/bmn) [[MMAction2 readthedocs]](https://mmaction2.readthedocs.io/en/latest/localization_models.html#bmn)

* BSN: Boundary Sensitive Network for Temporal Action Proposal Generation [[arXiv abstract]](https://arxiv.org/abs/1806.02964) [[pdf]](1806.02964) [[github code]](https://github.com/wzmsltw/BSN-boundary-sensitive-network.pytorch) [[MMAction2 readthedocs]](https://mmaction2.readthedocs.io/en/latest/localization_models.html#bsn)

* SSN: Temporal Action Detection with Structured Segment Networks [[arXiv abstract]](https://arxiv.org/abs/1704.06228) [[pdf]](1704.06228) [[MMAction2 readthedocs]](https://mmaction2.readthedocs.io/en/latest/localization_models.html#ssn)

* BSN++: Complementary Boundary Regressor with Scale-Balanced Relation Modeling for Temporal Action Proposal Generation [[arXiv abstract]](https://arxiv.org/abs/2009.07641) [[pdf]](2009.07641) [[github code]](https://github.com/xxcheng0708/BSNPlusPlus-boundary-sensitive-network)

* E2E-TAD: An Empirical Study of End-to-End Temporal Action Detection [[arXiv abstract]](https://arxiv.org/abs/2204.02932) [[pdf]](2204.02932) [[github code]](https://github.com/xlliu7/E2E-TAD)
  > After math of the TadTR work

* TadTR: End-to-end Temporal Action Detection with Transformer [[arXiv abstract]](https://arxiv.org/abs/2106.10271) [[pdf]](2106.10271) [[github code]](https://github.com/xlliu7/TadTR)
  > Improved on the work of E2E-TAD

* ASM-Loc: Action-aware Segment Modeling for Weakly-Supervised Temporal Action Localization [[arXiv abstract]](https://arxiv.org/abs/2203.15187) [[pdf]](2203.15187) [[github code]](https://github.com/boheumd/asm-loc)

* DBG Fast Learning of Temporal Action Proposal via Dense Boundary Generator [[arXiv abstract]](https://arxiv.org/abs/1911.04127) [[pdf]](1911.04127) [[github code]](https://github.com/Tencent/ActionDetection-DBG)

* TDN: Temporal Difference Networks for Efficient Action Recognition [[arXiv abstract]](https://arxiv.org/abs/2012.10071) [[pdf]](2012.10071) [[github code]](https://github.com/MCG-NJU/TDN)
  > Ranked #17 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tdn-temporal-difference-networks-for/action-recognition-in-videos-on-something)](https://paperswithcode.com/sota/action-recognition-in-videos-on-something?p=tdn-temporal-difference-networks-for)
  >
  > Ranked #5 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tdn-temporal-difference-networks-for/action-recognition-in-videos-on-something-1)](https://paperswithcode.com/sota/action-recognition-in-videos-on-something-1?p=tdn-temporal-difference-networks-for)

* ActionFormer: Localizing Moments of Actions with Transformers [[arXiv abstract]](https://arxiv.org/abs/2202.07925) [[pdf]](2202.07925) [[github code]](https://github.com/happyharrycn/actionformer_release)

* TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks [[arXiv abstract]](https://arxiv.org/abs/2011.11479) [[pdf]](2011.11479) [[github code]](https://github.com/HumamAlwassel/TSP)
  > Ranked #10 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tsp-temporally-sensitive-pretraining-of-video/temporal-action-localization-on-activitynet)](https://paperswithcode.com/sota/temporal-action-localization-on-activitynet?p=tsp-temporally-sensitive-pretraining-of-video)
  >
  > Ranked #3 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tsp-temporally-sensitive-pretraining-of-video/temporal-action-proposal-generation-on)](https://paperswithcode.com/sota/temporal-action-proposal-generation-on?p=tsp-temporally-sensitive-pretraining-of-video)
  >
  > Ranked #5 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tsp-temporally-sensitive-pretraining-of-video/dense-video-captioning-on-activitynet)](https://paperswithcode.com/sota/dense-video-captioning-on-activitynet?p=tsp-temporally-sensitive-pretraining-of-video)
  >
  > Ranked #8 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/tsp-temporally-sensitive-pretraining-of-video/temporal-action-localization-on-thumos14)](https://paperswithcode.com/sota/temporal-action-localization-on-thumos14?p=tsp-temporally-sensitive-pretraining-of-video)

* TALLFormer: Temporal Action Localization with a Long-memory Transformer [[arXiv abstract]](https://arxiv.org/abs/2204.01680) [[pdf]](2204.01680) [[github code]](https://github.com/klauscc/tallformer)

* AEI: Actors-Environment Interaction with Adaptive Attention for Temporal Action Proposals Generation [[arXiv abstract]](https://arxiv.org/abs/2110.11474) [[pdf]](2110.11474) [[github code]](https://github.com/vhvkhoa/tapg-agentenvinteration)
  > Ranked #1 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/aei-actors-environment-interaction-with/temporal-action-proposal-generation-on)](https://paperswithcode.com/sota/temporal-action-proposal-generation-on?p=aei-actors-environment-interaction-with)
  >
  > ⚠️ Requires environment and actor features doing respectively 80 and 215 GB!!

* RTD-Net: Relaxed Transformer Decoders for Direct Action Proposal Generation [[arXiv abstract]](https://arxiv.org/abs/2102.01894) [[pdf]](2102.01894) [[github code]](https://github.com/MCG-NJU/RTD-Action)

* TSM: Temporal Shift Module for Efficient Video Understanding [[arXiv abstract]](https://arxiv.org/abs/1811.08383) [[pdf]](1811.08383) [[github code]](https://github.com/mit-han-lab/temporal-shift-module)
  > it can achieve the performance of 3D CNN but maintain 2D CNN's complexity

* TSN: Temporal Segment Networks for Action Recognition in Videos [[arXiv abstract]](https://arxiv.org/abs/1705.02953) [[pdf]](1705.02953) [[github code]](https://github.com/yjxiong/temporal-segment-networks)

* UniVL: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation [[arXiv abstract]](https://arxiv.org/abs/2002.06353) [[pdf]](2002.06353) [[github code]](https://github.com/microsoft/UniVL)

* YOWO: You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization [[arXiv abstract]](https://arxiv.org/abs/1911.06644) [[pdf]](1911.06644) [[github code]](https://github.com/wei-tim/YOWO)
  > CNN architecture for real-time spatiotemporal action localization in video stream

* AFSD: Learning Salient Boundary Feature for Anchor-free Temporal Action Localization [[arXiv abstract]](https://arxiv.org/abs/2103.13137) [[pdf]](2103.13137) [[github code]](https://github.com/TencentYoutuResearch/ActionDetection-AFSD)
[[pretrained models - Google Drive]](https://drive.google.com/drive/folders/1IG51-hMHVsmYpRb_53C85ISkpiAHfeVg)

* SSTAP: Self-Supervised Learning for Semi-Supervised Temporal Action Proposal
[[arXiv abstract]](https://arxiv.org/abs/2104.03214) [[github code]](https://github.com/wangxiang1230/SSTAP)
[[SSTAP_TSN_Model_Weights | Zenodo]](https://zenodo.org/record/5036065#.Yv4HxuxBweb)

* MUSES: Multi-shot Temporal Event Localization: a Benchmark [[arXiv abstract]](https://arxiv.org/abs/2012.09434) [[pdf]](2012.09434) [[github code]](https://github.com/xlliu7/MUSES)
  > Ranked #5 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/multi-shot-temporal-event-localization-a/temporal-action-localization-on-thumos14)](https://paperswithcode.com/sota/temporal-action-localization-on-thumos14?p=multi-shot-temporal-event-localization-a)

* CoLA: Weakly-Supervised Temporal Action Localization with Snippet Contrastive Learning [[arXiv abstract]](https://arxiv.org/abs/2103.16392) [[pdf]](2103.16392) [[github code]](https://github.com/zhang-can/CoLA)

* TCANet: Temporal Context Aggregation Network for Temporal Action Proposal Refinement [[arXiv abstract]](https://arxiv.org/abs/2103.13141) [[pdf]](2103.13141) [[github code]](https://github.com/qinzhi-0110/Temporal-Context-Aggregation-Network-Pytorch)

* DCAN: Improving Temporal Action Detection via Dual Context Aggregation [[arXiv abstract]](https://arxiv.org/abs/2112.03612) [[pdf]](2112.03612) [[github code]](https://github.com/cg1177/DCAN)

* TAM: Temporal Adaptive Module for Video Recognition [[arXiv abstract]](https://arxiv.org/abs/2005.06803) [[pdf]](2005.06803) [[github code]](https://github.com/liu-zhy/temporal-adaptive-module)
  > Video data is with complex temporal dynamics due to various factors such as camera motion, speed variation, and different activities

* **End-to-end Learning of Action Detection from Frame Glimpses in Videos** [[arXiv abstract]](https://arxiv.org/abs/1511.06984) [[pdf]](1511.06984)
  > Seeks frames from variable distances, forward and as well backwards

* AdaFrame: Adaptive Frame Selection for Fast Video Recognition [[arXiv abstract]](https://arxiv.org/abs/1811.12432) [[pdf]](1811.12432)