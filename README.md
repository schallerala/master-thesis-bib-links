Related Work
============



## Related to CLIP (from OpenAI)

> CLIP itself: openai/CLIP: Contrastive Language-Image Pretraining [[github code]](https://github.com/openai/CLIP) [[arXiv abstract]](https://arxiv.org/abs/2103.00020)
> Inspiration:
> * [[Github Awesome CLIP]](https://github.com/yzhuoning/Awesome-CLIP) [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/yzhuoning/Awesome-CLIP)
> * [[Github Awesome Video Text Retrieval]](https://github.com/willard-yuan/video-text-retrieval-papers) [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/willard-yuan/video-text-retrieval-papers)
> * [[Papers with Code: Action Recognition]](https://paperswithcode.com/task/action-recognition)

> (_johanmodin/clifs: Contrastive Language-Image Forensic Search allows free text searching through videos using OpenAI's machine-learning model CLIP [[github code]](https://github.com/johanmodin/clifs)_)

> Popular Downstream Tasks for Video Representation Learning | by Madeline Schiappa | Towards Data Science [[towards data science]](https://towardsdatascience.com/popular-downstream-tasks-for-video-representation-learning-8edbd8dc19c1)


* Train-CLIP: A PyTorch Lightning solution to training OpenAI's CLIP from scratch [[github code]](https://github.com/Zasder3/train-CLIP)

* OpenCLIP: An open source implementation of CLIP [[github code]](https://github.com/mlfoundations/open_clip)

* KaiyangZhou/CoOp: Prompt Learning for Vision-Language Models [[github code]](https://github.com/KaiyangZhou/CoOp)
  * [Conditional Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2203.05557) [](2203.05557.pdf), in CVPR, 2022.
  * [Learning to Prompt for Vision-Language Models](https://arxiv.org/abs/2109.01134), arXiv, 2021.

* rmokady/CLIP_prefix_caption: Simple image captioning model
[[github code]](https://github.com/rmokady/CLIP_prefix_caption)
  > Could produce captions out of encoded images by CLIP (maybe work also for videos)

* gaopengcuhk/CLIP-Adapter [[github code]](https://github.com/gaopengcuhk/CLIP-Adapter) [[arXiv abstract]](https://arxiv.org/abs/2110.04544) [[pdf]](2110.04544.pdf)

* gaopengcuhk/Tip-Adapter [[github code]](https://github.com/gaopengcuhk/tip-adapter) [[arXiv abstract]](https://arxiv.org/abs/2111.03930) [[pdf]](2111.03930.pdf)

* CyCLIP: Cyclic Contrastive Language-Image Pretraining [[arXiv abstract]](https://arxiv.org/abs/2205.14459) [[pdf]](2205.14459.pdf)
[[github code]](https://github.com/megvii-research/protoclip)

* ZrrSkywalker/PointCLIP: [CVPR 2022] PointCLIP: Point Cloud Understanding by CLIP [[github code]](https://github.com/ZrrSkywalker/PointCLIP) [[arXiv abstract]](https://arxiv.org/abs/2112.02413) [[pdf]](2112.02413.pdf)

* sallymmx/ActionCLIP: This is the official implement of paper "ActionCLIP: A New Paradigm for Action Recognition" [[github code]](https://github.com/sallymmx/actionclip) [[arXiv abstract]](https://arxiv.org/abs/2109.08472) [[pdf]](2109.08472.pdf)

* _Align_: Scaling Up Visual and Vision-Language Representation Learning
With Noisy Text Supervision [[arXiv abstract]](https://arxiv.org/abs/2102.05918) [[pdf]](2102.05918.pdf)

* CLIP-TD: CLIP Targeted Distillation for Vision-Language Tasks [[arXiv abstract]](https://arxiv.org/abs/2201.05729v1) [[pdf]](2201.05729v1.pdf)

* ClipBERT: Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling [[github code]](https://github.com/jayleicn/ClipBERT) [[arXiv abstract]](https://arxiv.org/abs/2102.06183) [[pdf]](2102.06183.pdf)

* CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval [[github code]](https://github.com/ArrowLuo/CLIP4Clip) [[arXiv abstract]](https://arxiv.org/abs/2104.08860) [[pdf]](2104.08860.pdf)
  > Also present in the [Twohee Framework](https://towhee.io/video-text-embedding/clip4clip)

* Center Clip: Token Clustering for Efficient Text-Video Retrieval [[github code]](https://github.com/mzhaoshuai/CenterCLIP) [[arXiv abstract]](https://arxiv.org/abs/2205.00823) [[pdf]](2205.00823.pdf)

* antoine77340/S3D_HowTo100M: S3D Text-Video model trained on HowTo100M using MIL-NCE
[[github code]](https://github.com/antoine77340/S3D_HowTo100M)

* DRL: Disentangled Representation Learning for Text-Video Retrieval
 [[github code]](https://github.com/foolwood/DRL) [[arXiv abstract]](https://arxiv.org/abs/2203.07111) [[pdf]](2203.07111.pdf)
  > Available as a [[Towhee operator]](https://towhee.io/video-text-embedding/drl.pdf)

* Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval
[[github code]](https://github.com/m-bain/frozen-in-time) [[arXiv abstract]](https://arxiv.org/abs/2104.00650) [[pdf]](2104.00650.pdf)
  > Available as a [[Towhee operator]](https://towhee.io/video-text-embedding/frozen-in-time.pdf)

* CyCLIP: Cyclic Contrastive Language-Image Pretraining [[arXiv abstract]](https://arxiv.org/abs/2205.14459) [[pdf]](2205.14459.pdf)
[[github code]](https://github.com/goel-shashank/CyCLIP)

* SPOT: Semi-Supervised Temporal Action Detection with Proposal-Free Masking [[github code]](https://github.com/sauradip/SPOT) [[arXiv abstract]](https://arxiv.org/abs/2207.07059) [[pdf]](2207.07059.pdf)
  > **Also with Temporal Action Localization**
  >
  > Ranked #1 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/semi-supervised-temporal-action-detection/semi-supervised-action-detection-on)](https://paperswithcode.com/sota/semi-supervised-action-detection-on?p=semi-supervised-temporal-action-detection)
  >
  > Ranked #1 [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/semi-supervised-temporal-action-detection/semi-supervised-action-detection-on-thumos-14)](https://paperswithcode.com/sota/semi-supervised-action-detection-on-thumos-14?p=semi-supervised-temporal-action-detection)

* STALE: Zero-Shot Temporal Action Detection via Vision-Language Prompting [[github code]](https://github.com/sauradip/stale) [[arXiv abstract]](https://arxiv.org/abs/2207.08184) [[pdf]](2207.08184.pdf)

* singularity: Revealing Single Frame Bias for Video-and-Language Learning [[github code]](https://github.com/jayleicn/singularity) [[arXiv abstract]](https://arxiv.org/abs/2206.03428) [[pdf]](2206.03428.pdf)

* SlowFast: video understanding codebase from FAIR for reproducing [[github code]](https://github.com/facebookresearch/SlowFast) [[arXiv abstract]](https://arxiv.org/abs/1812.03982) [[pdf]](1812.03982.pdf) [[arXiv abstract X3D: Progressive Network Expansion for Efficient Video Recognition]](https://arxiv.org/abs/2004.04730.pdf)

* AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition [[github code]](https://github.com/LeapLabTHU/AdaFocusV2) [[arXiv abstract]](https://arxiv.org/abs/2112.14238) [[pdf]](2112.14238.pdf) [[weights gdrive]](https://drive.google.com/drive/folders/1ETQb7aOGb4bePhVP82vFB24pqgn0UAkV.pdf)

* MViTv2: Improved Multiscale Vision Transformers for Classification and Detection [[github code]](https://github.com/facebookresearch/mvit) [[arXiv abstract]](https://arxiv.org/abs/2112.01526) [[pdf]](2112.01526.pdf)

* MoViNets: Mobile Video Networks for Efficient Video Recognition [[github code]](https://github.com/Atze00/MoViNet-pytorch) [[arXiv abstract]](https://arxiv.org/abs/2103.11511) [[pdf]](2103.11511.pdf)

* ViViT: A Video Vision Transformer
 [[github code by Scenic]](https://github.com/google-research/scenic/tree/main/scenic/projects/vivit) [[arXiv abstract]](https://arxiv.org/abs/2103.15691) [[pdf]](2103.15691.pdf)

* DE:TR</span>: End-to-End Object Detection with Transformers
 [[github code]](https://github.com/facebookresearch/detr) [[arXiv abstract]](https://arxiv.org/abs/2005.12872) [[pdf]](2005.12872.pdf)

* VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding [[github code]](https://github.com/facebookresearch/fairseq/tree/main/examples/MMPT) [[arXiv abstract]](https://arxiv.org/abs/2109.14084) [[pdf]](2109.14084.pdf)

* BridgeFormer: Bridging Video-text Retrieval with Multiple Choice Questions [[arXiv abstract]](https://arxiv.org/abs/2201.04850) [[pdf]](2201.04850.pdf) [[github code]](https://github.com/tencentarc/mcq)
  > It is also available as a [Towhee operator](https://towhee.io/video-text-embedding/bridge-former)



## Temporal localization

> See dedicated subfolder: [`./temporal_localization`](temporal_localization/README.md)


## Others

* Robust fine-tuning of zero-shot models (by ML Foundations) [[github code]](https://github.com/mlfoundations/wise-ft) [[arXiv abstract]](https://arxiv.org/abs/2109.01903) [[pdf]](2109.01903.pdf)


* t-SNE clearly explained. An intuitive explanation of t-SNEâ€¦ | by Kemal Erdem (burnpiro) | Towards Data Science
[[towards data science]](https://towardsdatascience.com/t-sne-clearly-explained-d84c537f53a)

* All About ML â€” Part 8: Understanding Principal Component Analysis â€” PCA | by Dharani J | All About ML [[Medium]](https://medium.com/all-about-ml/understanding-principal-component-analysis-pca-556778324b0e)
  > ... data sets that have more than 20 features or high dimensional data. To check the correlation between them, we might have to visualize 20C2 = 190 2D scatter plots! Thatâ€™s a lot to visualize. On top of that, most of them will not be informative. Clearly if we have many features it gets clumsy to analyze the features and understand their relations. Rather than analyzing each pair from many, if we can try to reduce the dimension to a small range by capturing all the information then we can effortlessly get insights from data.

* Vision optimization:

  * A Simple Cache Model for Image Recognition
  [[arXiv abstract]](https://arxiv.org/abs/1805.08709) [[pdf]](1805.08709.pdf) [[github code]](https://github.com/eminorhan/simple-cache)

  * KD-Lib: A PyTorch library for Knowledge Distillation, Pruning and Quantization
  [[arXiv abstract]](https://arxiv.org/abs/2011.14691) [[pdf]](2011.14691.pdf)

  * [[github code]](https://github.com/urvashik/knnlm)

* Feature Pyramid Networks for Object Detection [[arXiv abstract]](https://arxiv.org/abs/1612.03144) [[pdf]](1612.03144.pdf)

* lucidrains/discrete-key-value-bottleneck-pytorch: Implementation of Discrete Key / Value Bottleneck, in Pytorch
[[github code]](https://github.com/lucidrains/discrete-key-value-bottleneck-pytorch)

* Using ffprobe to get info from a file in a nice JSON format [[gist]](https://gist.github.com/nrk/2286511)
  > `ffprobe -v quiet -print_format json -show_format -show_streams "lolwut.mp4" > "lolwut.mp4.json"`

* deepdraw/deepdraw.ipynb at master Â· auduno/deepdraw
[[github code]](https://github.com/auduno/deepdraw/blob/master/deepdraw.ipynb)

* Mean-Average-Precision (mAP)
  * Mean-Average-Precision (mAP) â€” PyTorch-Metrics 0.9.3 documentation [[readthedocs]](https://torchmetrics.readthedocs.io/en/stable/detection/mean_average_precision.html)

  * mAP (mean Average Precision) for Object Detection | by Jonathan Hui [[Medium]](https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173)


### Datasets

> Security and i-LIDS Dataset topics are presented in the [/i-LIDS subfolder](i-LIDS)


* [VIRAT Video Data](https://viratdata.org/#getting-data)
  * [Files Â· master Â· viratdata / viratannotations Â· GitLab](https://gitlab.kitware.com/viratdata/viratannotations/-/tree/master/)
  * [documents/KPF-specification-v4.pdf Â· master Â· MEVA / meva-data-repo Â· GitLab](https://gitlab.kitware.com/meva/meva-data-repo/-/blob/master/documents/KPF-specification-v4.pdf)
  * [TinyVIRAT: Low-resolution Video Action Recognition â€“ Center for Research in Computer Vision](https://www.crcv.ucf.edu/research/projects/tinyvirat-low-resolution-video-action-recognition/)

* [Jean-Marc Odobez - Home Page - IDIAP Research Institute: Traffic Junction](https://www.idiap.ch/~odobez/RESSOURCES/DataRelease-TrafficJunction.php)


### MLOps

> [MLOps Toys | A Curated List of Machine Learning Projects](https://mlops.toys/)

* Aim: easy-to-use and performant open-source ML experiment tracker.
[[official website]](https://aimstack.io/)
  > Open Source

* BentoML: A faster way to ship your models to production [[official website]](https://www.bentoml.com/)
  > Open Source

* Data Version Control Â· DVC [[official website]](https://dvc.org/)
  > Open Source
  >
  > by iterative.ai

* Home | MLEM [[official website]](https://mlem.ai/)
  > Open Source
  >
  > by iterative.ai
  >
  > Open-source tool to simplify ML model deployment: Save your ML model with a Python call, Model metadata is captured automatically, Deploy models anywhere you want, make git a Model Registry

* Weights & Biases â€“ Developer tools for ML [[official website]](https://wandb.ai/site)
  > The developer-first â€MLOps platform
  >
  > Build better models faster with experiment tracking, dataset versioning, and model management

* Home - neptune.ai [[official website]](https://neptune.ai/home)
  > Track experiments. Register models. Integrate with any MLOps stack.

* Aporia - Cloud Native ML Observability | Monitor your Models [[official website]](https://www.aporia.com/)


* _Blog posts_:
  * Machine Learning Model Management: What It Is, Why You Should Care, and How to Implement It - neptune.ai [[ðŸ“ blog]](https://neptune.ai/blog/machine-learning-model-management)

  * ML Experiment Tracking: What It Is, Why It Matters, and How to Implement It - neptune.ai [[ðŸ“ blog]](https://neptune.ai/blog/ml-experiment-tracking)

  * Model Deployment Challenges: 6 Lessons From 6 ML Engineers - neptune.ai [[ðŸ“ blog]](https://neptune.ai/blog/model-deployment-challenges-lessons-from-ml-engineers)

  * ML Metadata Store: What It Is, Why It Matters, and How to Implement It - neptune.ai [[ðŸ“ blog]](https://neptune.ai/blog/ml-metadata-store)


#### Tools

* MayaData | Data Agility Delivered [[official website]](https://mayadata.io/)
  > Bring Your Data to Kubernetes
  >
  > Donâ€™t let an outdated data layer be your bottleneck. Run stateful workloads on Kubernetes, save money and move faster.
  >
  > We make leading open source, high performance, and cloud native solutions.

* Milvus
  * [2021SIGMOD-Milvus](https://www.cs.purdue.edu/homes/csjgwang/pubs/SIGMOD21_Milvus.pdf)
  * Vector database - Milvus [[official website]](https://milvus.io/)
  * milvus-io/milvus: Vector database for scalable similarity search and AI applications.
  [[github code]](https://github.com/milvus-io/milvus)


### Model monitoring

* What is the difference between outlier detection and data drift detection? | by Elena Samuylova | Towards Data Science
[[towards data science]](https://towardsdatascience.com/what-is-the-difference-between-outlier-detection-and-data-drift-detection-534b903056d4)

* Drift in Machine Learning. Why is it hard and what to do about it? | by Piotr (Peter) Mardziel | Towards Data Science
[[towards data science]](https://towardsdatascience.com/drift-in-machine-learning-e49df46803a)


### Learning

* [Chapter 4: Neural networks and deep learning](http://neuralnetworksanddeeplearning.com/chap4.html)

* [Chapter 5: Neural networks and deep learning](http://neuralnetworksanddeeplearning.com/chap5.html)

* [Lecture 5: Convolutional Neural Networks -- Stanford](http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture05.pdf)

* [The Ultimate Guide to Word Embeddings - neptune.ai](https://neptune.ai/blog/word-embeddings-guide)

* [Understanding Representation Learning With Autoencoder - neptune.ai](https://neptune.ai/blog/representation-learning-with-autoencoder)

* [An Intuitive Introduction to Deep Autoregressive Networks - ML@B Blog](https://ml.berkeley.edu/blog/posts/AR_intro/)


### Optimization

* [Mixed precision | TensorFlow Core](https://www.tensorflow.org/guide/mixed_precision)

* Understanding Mixed Precision Training | by Jonathan Davis | Towards Data Science
[[towards data science]](https://towardsdatascience.com/understanding-mixed-precision-training-4b246679c7c4)

* [Mixed precision: What is mixed precision training?](https://keras.io/api/mixed_precision/)

* A Survey of Quantization Methods for Efficient Neural Network Inference [[arXiv abstract]](https://arxiv.org/abs/2103.13630) [[pdf]](2103.13630.pdf)

* [PyTorch Model Inference using ONNX and Caffe2 | LearnOpenCV](https://learnopencv.com/pytorch-model-inference-using-onnx-and-caffe2/)

* Ki6an/fastT5: âš¡ boost inference speed of T5 models by 5x & reduce the model size by 3x.
[[github code]](https://github.com/Ki6an/fastT5)

* peterliht/knowledge-distillation-pytorch: A PyTorch implementation for exploring deep and shallow knowledge distillation (KD) experiments with flexibility
[[github code]](https://github.com/peterliht/knowledge-distillation-pytorch)

* zhutmost/lsq-net: Unofficial implementation of LSQ-Net, a neural network quantization framework
[[github code]](https://github.com/zhutmost/lsq-net)

* Introduction to PyTorch Model Compression Through Teacher-Student Knowledge Distillation | by Moussa Taifi PhD | Towards Data Science
[[towards data science]](https://towardsdatascience.com/model-distillation-and-compression-for-recommender-systems-in-pytorch-5d81c0f2c0ec)

#### IO

* Comparison between LMDB and RocksDB
  * [LevelDB vs. LMDB vs. RocksDB Comparison](https://db-engines.com/en/system/LMDB%3BLevelDB%3BRocksDB)
  * [Benchmarking LevelDB vs. RocksDB vs. HyperLevelDB vs. LMDB Performance for InfluxDB | InfluxData](https://www.influxdata.com/blog/benchmarking-leveldb-vs-rocksdb-vs-hyperleveldb-vs-lmdb-performance-for-influxdb/)
  * [_LMDB oriented_] Scalable Deep Learning via I/O Analysis and Optimization [[online pdf]](https://synergy.cs.vt.edu/pubs/papers/pumma-lmdbio-dio-topc19.pdf) [[pdf]](sensors-22-03601-v2.pdf)
  * [_LMDB oriented_] Efficiently processing large image datasets in Python
  [[:pencil: blog]](https://www.pankesh.com/_posts/2019-05-18-efficiently-storing-and-retrieving-image-datasets.html)

* jnwatson/py-lmdb: Universal Python binding for the LMDB 'Lightning' Database
[[github code]](https://github.com/jnwatson/py-lmdb/)

* facebook/rocksdb: A library that provides an embeddable, persistent key-value store for fast storage.
[[github code]](https://github.com/facebook/rocksdb/)

  * [RocksDB - Database of Databases](https://dbdb.io/db/rocksdb)

  * nni/RocksdbExamples.rst at v2.0 Â· microsoft/nni [[NNI github readme]](https://github.com/Microsoft/nni/blob/v2.0/docs/en_US/TrialExample/RocksdbExamples.rst)


### Libs

* dmlc/decord: An efficient video loader for deep learning with smart shuffling that's super easy to digest
[[github code]](https://github.com/dmlc/decord)

* Welcome to âš¡ PyTorch Lightning â€” PyTorch Lightning 1.8.0dev documentation [[readthedocs]](https://pytorch-lightning.readthedocs.io/en/latest/)

  * Build a Model â€” PyTorch Lightning 1.8.0dev documentation [[readthedocs]](https://pytorch-lightning.readthedocs.io/en/latest/model/build_model.html)

* [Towhee | Home - Towhee](https://towhee.io/)
  * [action-classification/movinet - movinet - Towhee](https://towhee.io/action-classification/movinet)
  * [Towhee | Operator Task Detail - Towhee](https://towhee.io/tasks/detail/operator?field_name=Multimodal&task_name=Video/Text-Embedding)
    * [video-text-embedding/clip4clip - clip4clip - Towhee](https://towhee.io/video-text-embedding/clip4clip)

* Welcome to TorchMetrics â€” PyTorch-Metrics 0.9.3 documentation [[readthedocs]](https://torchmetrics.readthedocs.io/en/stable/)

* streamlit/streamlit: Streamlit â€” The fastest way to build data web apps in Python
[[github code]](https://github.com/streamlit/streamlit)

* msamogh/nonechucks: Deal with bad samples in your dataset dynamically, use Transforms as Filters, and more! [[github code]](https://github.com/msamogh/nonechucks)

* [Altair: Declarative Visualization in Python â€” Altair 4.2.0 documentation](https://altair-viz.github.io/)


### Other Computer Vision tasks/concepts

* [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/)
  * [Introduction to YOLO Algorithm for Object Detection | Engineering Education (EngEd) Program | Section](https://www.section.io/engineering-education/introduction-to-yolo-algorithm-for-object-detection/)

* [Optical flow - Wikipedia](https://en.wikipedia.org/wiki/Optical_flow)

* [Introduction to Motion Estimation with Optical Flow](https://nanonets.com/blog/optical-flow/)

* [OpenCV: Optical Flow](https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html)

* facebookresearch/detectron2: Detectron2 is a platform for object detection, segmentation and other visual recognition tasks.
[[github code]](https://github.com/facebookresearch/detectron2)

* Image derivative. Analysis of the first derivative of anâ€¦ | by Giuseppe Pio Cannata | Towards Data Science
[[towards data science]](https://towardsdatascience.com/image-derivative-8a07a4118550)

### Writting Thesis

* [Dissertation/Thesis Guide](http://www.learnerassociates.net/dissthes/)

* [Thoughts on the Structure of CS Dissertations](https://www.cc.gatech.edu/fac/Spencer.Rugaber/txt/thesis.html)

* [paper-reading-technical.pdf Stanford](https://cs.stanford.edu/~rishig/courses/ref/paper-reading-technical.pdf)

* [10 tips on how to give an academic talk](https://matt.might.net/articles/academic-presentation-tips/)